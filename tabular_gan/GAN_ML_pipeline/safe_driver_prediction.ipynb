{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark quality of synthetic data generated using GANs on a predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "Nothing ruins the thrill of buying a brand new car more quickly than seeing your new insurance bill. The sting’s even more painful when you know you’re a good driver. It doesn’t seem fair that you have to pay so much if you’ve been cautious on the road for years.\n",
    "\n",
    "Porto Seguro, one of Brazil’s largest auto and homeowner insurance companies, completely agrees. Inaccuracies in car insurance company’s claim predictions raise the cost of insurance for good drivers and reduce the price for bad ones.\n",
    "\n",
    "For more details refer [here](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/overview).\n",
    "\n",
    "### Objective\n",
    "\n",
    "Build a model that predicts the probability that a driver will initiate an auto insurance claim in the next year. Given that the sample class of drivers initiating auto insurance is biased, augment data using GANs and other methods to improve accuracy and stabilise the predictive model. Compare the accuracy/ stability before and after data augmentation which serves as a proxy for the quality of synthetic data generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "\n",
    "from ctgan import CTGANSynthesizer\n",
    "\n",
    "# Use conda install scikit-learn to overcome sklearn testing import issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "test = pd.read_csv('data/porto_seguro_safe_driver/test.csv')  # to test the predictions in the test set, install Kaggle API and run it on the competition kernel\n",
    "train = pd.read_csv('data/porto_seguro_safe_driver/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "\n",
    "def filling_missing_values(data):\n",
    "    '''A function to fill in the missing values of categorical features'''\n",
    "    for i in data.columns.values:\n",
    "        if data.isnull().values.any():\n",
    "            if i == 'ps_car_03_cat' or i == 'ps_car_05_cat':\n",
    "                continue\n",
    "            elif i == 'ps_ind_05_cat' or i == 'ps_car_07_cat':\n",
    "                data[i].fillna(data[i].mode()[0], inplace=True)\n",
    "            else:\n",
    "                data[i].fillna(data[i].mean(), inplace=True)\n",
    "        else:\n",
    "            continue\n",
    "    return data\n",
    "\n",
    "\n",
    "# Determine missing values in each column of the given dataframe\n",
    "def missing_values(data):\n",
    "    '''Function to find the percentage of missing values in each column of a DataFrame passed'''\n",
    "    for i in data.columns.values:\n",
    "        count =  data[data[i] == -1].shape[0]\n",
    "        print(\"Missing Values in '{}' : {:.4f} %\".format(i, (count/data.shape[0])*100))\n",
    "        \n",
    "\n",
    "train = train.replace(-1, np.nan)\n",
    "train = train.replace(-1, np.nan)\n",
    "        \n",
    "# Fill missing values in train and test        \n",
    "train = filling_missing_values(train)\n",
    "test = filling_missing_values(test)       \n",
    "\n",
    "# Check for missing values after filling\n",
    "# missing_values(train)\n",
    "# missing_values(test)\n",
    "\n",
    "# Drop columns that are not needed\n",
    "col_to_drop = list(train.columns[train.columns.str.startswith('ps_calc_')])\n",
    "# Drop columns that are missing a lot as values\n",
    "col_to_drop += ['ps_car_03_cat', 'ps_car_05_cat']\n",
    "train = train.drop(col_to_drop, axis=1)  \n",
    "test = test.drop(col_to_drop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  out = sparse.csr_matrix((data, indices, indptr),\n",
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  out = sparse.csr_matrix((data, indices, indptr),\n",
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  out = sparse.csr_matrix((data, indices, indptr),\n",
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  out = sparse.csr_matrix((data, indices, indptr),\n",
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  out = sparse.csr_matrix((data, indices, indptr),\n",
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  out = sparse.csr_matrix((data, indices, indptr),\n",
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  out = sparse.csr_matrix((data, indices, indptr),\n",
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  out = sparse.csr_matrix((data, indices, indptr),\n",
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  out = sparse.csr_matrix((data, indices, indptr),\n",
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  out = sparse.csr_matrix((data, indices, indptr),\n",
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  out = sparse.csr_matrix((data, indices, indptr),\n",
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  out = sparse.csr_matrix((data, indices, indptr),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G: 1.3501, Loss D: 0.1074\n",
      "Epoch 2, Loss G: 0.8529, Loss D: -0.1343\n",
      "Epoch 3, Loss G: 0.3041, Loss D: 0.1112\n",
      "Epoch 4, Loss G: 0.2197, Loss D: 0.0399\n",
      "Epoch 5, Loss G: -0.1111, Loss D: 0.2283\n"
     ]
    }
   ],
   "source": [
    "# Generate data using GANs to handle class imbalance\n",
    "\n",
    "# Preprocess data \n",
    "\n",
    "train_gen = train.loc[train.target==1, train.columns != 'target'].copy()\n",
    "train_gen = train_gen.drop(['id'], axis=1)\n",
    "\n",
    "# List of categorical features\n",
    "cat_features = [a for a in train_gen.columns if a.endswith('cat')]\n",
    "\n",
    "ctgan = CTGANSynthesizer()\n",
    "ctgan.fit(train_gen, cat_features, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 37)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_car_09_cat</th>\n",
       "      <th>ps_car_10_cat</th>\n",
       "      <th>ps_car_11_cat</th>\n",
       "      <th>ps_car_11</th>\n",
       "      <th>ps_car_12</th>\n",
       "      <th>ps_car_13</th>\n",
       "      <th>ps_car_14</th>\n",
       "      <th>ps_car_15</th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.877373</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353685</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989327</td>\n",
       "      <td>1.015544</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>1.013882</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.972799</td>\n",
       "      <td>0.401574</td>\n",
       "      <td>1.732962</td>\n",
       "      <td>0.361390</td>\n",
       "      <td>3.426562</td>\n",
       "      <td>generated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.972134</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.888083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>-0.010918</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>-0.007671</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2.015437</td>\n",
       "      <td>0.449782</td>\n",
       "      <td>1.015299</td>\n",
       "      <td>0.459155</td>\n",
       "      <td>3.432269</td>\n",
       "      <td>generated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.969146</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.089348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001497</td>\n",
       "      <td>0.987894</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.993559</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.980083</td>\n",
       "      <td>0.375507</td>\n",
       "      <td>0.896821</td>\n",
       "      <td>0.344558</td>\n",
       "      <td>3.462962</td>\n",
       "      <td>generated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.079132</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.175427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011330</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.004126</td>\n",
       "      <td>0.376327</td>\n",
       "      <td>0.902693</td>\n",
       "      <td>0.359034</td>\n",
       "      <td>3.585055</td>\n",
       "      <td>generated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.878365</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.974337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>-0.012287</td>\n",
       "      <td>-0.001791</td>\n",
       "      <td>0.009415</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.009672</td>\n",
       "      <td>0.449358</td>\n",
       "      <td>0.946038</td>\n",
       "      <td>0.387174</td>\n",
       "      <td>2.693171</td>\n",
       "      <td>generated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "0   4.877373            1.0   0.353685            1.0            0.0   \n",
       "1   0.972134            3.0   2.888083            0.0            0.0   \n",
       "2   0.969146            2.0   3.089348            1.0            0.0   \n",
       "3   2.079132            2.0   7.175427            1.0            0.0   \n",
       "4   2.878365            4.0   4.974337            0.0            0.0   \n",
       "\n",
       "   ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ps_ind_10_bin  \\\n",
       "0       0.989327       1.015544       0.004155       1.013882       0.001548   \n",
       "1       0.009558      -0.010918       0.005899      -0.007671       0.003505   \n",
       "2      -0.001497       0.987894       0.001142       0.993559       0.001119   \n",
       "3       0.011330       0.002391       0.002441      -0.001652       0.000001   \n",
       "4       0.011478      -0.012287      -0.001791       0.009415      -0.000182   \n",
       "\n",
       "   ...  ps_car_09_cat  ps_car_10_cat  ps_car_11_cat  ps_car_11  ps_car_12  \\\n",
       "0  ...            0.0            1.0           65.0   1.972799   0.401574   \n",
       "1  ...            0.0            1.0          104.0   2.015437   0.449782   \n",
       "2  ...            1.0            1.0            5.0   2.980083   0.375507   \n",
       "3  ...            2.0            1.0           87.0   2.004126   0.376327   \n",
       "4  ...            2.0            1.0            1.0   2.009672   0.449358   \n",
       "\n",
       "   ps_car_13  ps_car_14  ps_car_15         id  target  \n",
       "0   1.732962   0.361390   3.426562  generated       1  \n",
       "1   1.015299   0.459155   3.432269  generated       1  \n",
       "2   0.896821   0.344558   3.462962  generated       1  \n",
       "3   0.902693   0.359034   3.585055  generated       1  \n",
       "4   0.946038   0.387174   2.693171  generated       1  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding 30000 samples to train dataset\n",
    "samples = ctgan.sample(30000)\n",
    "samples['id'] = 'generated'\n",
    "samples['target'] = 1\n",
    "print(samples.shape)\n",
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append to train data\n",
    "train = pd.concat([train, samples], axis=0, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 500169 & Validation samples: 125043\n",
      "\n",
      " 0    458781\n",
      "1     41388\n",
      "Name: target, dtype: int64\n",
      "0    114737\n",
      "1     10306\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Take a random 20% of the dataset as validation data\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train, train['target'], test_size=0.2, random_state=1243)\n",
    "print('Train samples: {} & Validation samples: {}'.format(len(x_train), len(x_valid)))\n",
    "print('\\n', y_train.value_counts())\n",
    "print(y_valid.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500169, 206) (125043, 206) (892816, 206)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing \n",
    "id_valid = x_valid['id'].values\n",
    "id_test = test['id'].values\n",
    "target_train = x_train['target'].values\n",
    "target_valid = x_valid['target'].values\n",
    "\n",
    "x_train = x_train.drop(['target','id'], axis = 1)\n",
    "x_valid = x_valid.drop(['id', 'target'], axis = 1)\n",
    "test = test.drop(['id'], axis = 1) \n",
    "\n",
    "def one_hot_encoding(df):\n",
    "    cat_features = [a for a in df.columns if a.endswith('cat')]\n",
    "\n",
    "    for column in cat_features:\n",
    "        temp = pd.get_dummies(pd.Series(df[column]))\n",
    "        df = pd.concat([df,temp],axis=1)\n",
    "        df = df.drop([column],axis=1)\n",
    "    return df\n",
    "\n",
    "x_train['flag'] = 'train'\n",
    "x_valid['flag'] = 'valid'\n",
    "test['flag'] = 'test'\n",
    "\n",
    "total = x_train.append([x_valid, test])\n",
    "total_coded = one_hot_encoding(total.loc[:, total.columns != 'flag'])\n",
    "total_coded['flag'] = total['flag']\n",
    "\n",
    "x_train = total_coded.loc[total_coded.flag=='train', total_coded.columns != 'flag']\n",
    "x_valid = total_coded.loc[total_coded.flag=='valid', total_coded.columns != 'flag']\n",
    "test = total_coded.loc[total_coded.flag=='test', total_coded.columns != 'flag']\n",
    "\n",
    "print(x_train.values.shape, x_valid.values.shape, test.values.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble model class\n",
    "class Ensemble(object):\n",
    "    def __init__(self, stacker, base_models):\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def fit_predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "            clf.fit(X, y)\n",
    "            S_train[:, i]= clf.predict_proba(X)[:,1]                \n",
    "            S_test[:, i] = clf.predict_proba(T)[:,1]\n",
    "            # S_test = S_test.mean(axis=1)\n",
    "\n",
    "        results = cross_val_score(self.stacker, S_train, y, cv=3, scoring='roc_auc')\n",
    "        print(\"Stacker score: %.5f\" % (results.mean()))\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        res = self.stacker.predict_proba(S_test)[:,1]\n",
    "        return res\n",
    "    \n",
    "# RandomForest params\n",
    "rf_params = {}\n",
    "rf_params['n_estimators'] = 200\n",
    "rf_params['max_depth'] = 6\n",
    "rf_params['min_samples_split'] = 70\n",
    "rf_params['min_samples_leaf'] = 30\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacker score: 0.82839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/gan_env/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "\n",
    "# Stacking model here is logistic regression \n",
    "log_model = LogisticRegression()\n",
    "\n",
    "# Base models - Random Forest and logistic regression\n",
    "random_forest_model = RandomForestClassifier(**rf_params)\n",
    "        \n",
    "stack = Ensemble(stacker = log_model,\n",
    "        base_models = (log_model, random_forest_model))        \n",
    "        \n",
    "y_pred = stack.fit_predict(x_train, target_train, x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[114737,      0],\n",
       "       [  4330,   5976]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Currently the threshold is taken to be 0.5\n",
    "y_pred[y_pred>=0.5] = 1\n",
    "y_pred[y_pred<0.5] = 0\n",
    "\n",
    "accuracy_score(target_valid, y_pred)\n",
    "confusion_matrix(target_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[114737,      0],\n",
       "       [     0,  10306]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original matrix\n",
    "confusion_matrix(target_valid, target_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without sampling the confusion matrix looks as below\n",
    "\n",
    "# array([[114729,      8],\n",
    "#        [     4544,  8]])\n",
    "\n",
    "# roc_auc improved from 0.62 to 0.82"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
